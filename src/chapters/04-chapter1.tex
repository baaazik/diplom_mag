\chapter{АНАЛИЗ ПРЕДМЕТНОЙ ОБЛАСТИ РЕКОМЕНДАТЕЛЬНЫХ СИСТЕМ}
\label{chap:analysis}
\aftertitle

\section{Понятие рекомендательных систем}

Задача фильтрации новостей и сообщений в групповых чатах решается рекомендательными системами. Рекомендательная система ~--  программная система, которая пытается предсказать, какие объекты (фильмы, музыка, книги, новости, веб-сайты) будут интересны пользователю, имея определенную информацию о его профиле \cite{recommendation_system_wiki}.

Существует несколько традиционных подходов к построению рекомендательных систем \cite{recommendation_system_methods}: контент-ориентированный подход и коллаборативная фильтрация.

Суть контент-ориентированного подхода заключается в сопоставлении аттрибутов контента и пользователей. Например, здесь могут быть использованы категориальные аттрибуты (жанр фильма, актеры фильма и т.п.), числовые аттрибуты (продолжительность, рейтинг и т.п.) для составления эмбеддингов или вектора предмета ~-- векторных представлений объекта рекомендации. Аналогично составляется вектор пользователя. Построив эмбеддинги пользователя и объектов, можно осуществлять рекомендации. Объект рекомендуется пользователю, если его эмбеддинги близки к эмбеддингам пользователя, либо к эмбеддингам других объектов, купленных (просмотренных, прочитанных и т.п.) пользователем.

В качестве эмбеддингов могут выступать и различные текстовые описания. В классических рекомендательных системах могут использоваться такие методы, как TF-IDF \cite{no-patterns}, а в современных рекомендательных системах ~-- текстовые эмбеддинги, полученные с помощью больших языковых моделей \cite{tf_augumenting_recommendation}.

В последнее время активно развиваются подходы с использованием больших языковых моделей в рекомендательных системах.

\section{Развитие методов обработки естественного языка}

Большая языковая модель (Large Language Model, LLM) ~-- искусственная нейронная сеть, предназначенная для обработки и понимания естественного языка (natural language processing).

Языковые модели являются одним из способов решения задач обработки естественного языка и генерации текста. Языковые модели моделируют естественный язык путем генерации следующих или пропущенных слов в текстовых последовательностях. Развитие языковых моделей можно разделить на следующие этапы: статистические модели, базовые нейросетевые модели, предобученные модели и большие языковые модели \cite{llm_survey}. Эти этапы развития языковых моделей представлены на рисунке \ref{img:llm_evolution}.

\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{../images/llm_evolution.png}
    \caption{Развитие языковых моделей с точки зрения объема решаемых задач\cite{llm_survey}}
    \label{img:llm_evolution}
\end{figure}

Статистические модели основаны на классических методах машинного обучения и статистики. Типичным подходом к языковому моделированию являлось использованием марковских цепей для предсказания следующих элементов последовательности. Такие модели, имеющие фиксированный контекст из нескольких предыдущих элементов, называются n-gram моделями.

Следующим шагом в развитии языковых моделей стало использование искусственных нейронных сетей (сетей прямого распространения и рекуррентных нейронных сетей). Важным шагом стало создание векторных представлений слов (эмбеддингов), таких как word2vec \cite{word2vec}. Этот метод позволяет представлять слова текста в виде векторов, близость которых отражает семантическую близость слов. Подход word2vec основан на гипотезе локальности, которая утверждает, что слова, которые встречаются в одинаковых окружениях, имеют близкие значения. Этот и подобные методы продемонстрировали высокую эффективность в различных задачах обработки естественного языка. Подход с использованием нейронных сетей, в основном, рекуррентных нейронных сетей RNN и LSTM, позволил реализовать end-to-end модели, решающие различные типичные задачи обработки естественного языка.

Дальнейшим развитием этих принципов стали предобученные языковые модели. В отличие от word2vec, который обучается независимым от контекста представлениям, языковые модели способны понимать значение слова с учетом окружающего контекста.

Первой попыткой создания контекстуальных эмбеддингов стал Elmo \cite{elmo}. Эта модель способна запоминать представления слов, зависящие от контекста. Эта модель основана на архитектуре двусторонней LSTM.

Важным шагом в развитии моделей обработки естесственного языка и в целом последовательностей стало появление архитектуры Трансформер \cite{transformer}. Трансформер представляет собой sequence-to-sequence модель, преобразующую текст (последовательность токенов) в другую последовательность токенов. Архитектурно он состоит из стека энкодеров, которые кодируют последовательность в некое внутреннее представление, и стека декодеров, которые генерируют новую последовательность. Важнейшим компонентом архитектуры Трансформера является механизм внимания (attention). Это механизм, который позволяет определять взаимную значимость токенов в последовательности, тем самым, позволяя лучше выстраивать связи между токенами (словами), которые расположены далеко друг от друга. Ключевым вкладом архитектуры Трансформера был отказ от использования рекуррентных нейронных сетей и использование только лишь механизма внимания. Это позволило существенно улучшить вычислительную производительность модели и ее возможность к удержанию большого контекста, что, в свою очередь, дало возможным создавать большие модели, состоящие из десятков миллиардов параметров, что было бы невозможно с использованием рекуррентных нейронных сетей.

С тех пор, архитектура Трансформер является основной архитектурой всех новейших state-of-the-art моделей по обработке естественного языка. На основе Трансформера были созданы такие получившие широкое распространение архитектуры как BERT \cite{bert} и GPT \cite{gpt}.

Важной особенностью этих моделей является возможность использования трансферного обучения (transfer learning). Трансферное обучение ранее широко применялось в задачах компьютерного зрения. Суть данного метода заключается в использовании базовой модели, называемой backbone, которая обучена на большом количестве общих данных, которая затем до-обучается на конкретных данных, специфичных для решаемой задачи. Это техника позволяет использовать очень глубокие нейронные сети, которые требуют большой объем обучающих данных и значительные вычислительные ресурсы для обучения.

Языковые модели обучаются с помощью техники self-supervised learning. Существуют различные методики обучения, такие как MLM (masked language modeling), CLM (casual language modeling) и др. В случае MLM некоторые слова (токены) в тексте заменяются на маску, задачей модели является предсказать закрытый токен. В случае CLM задачей модели является предсказать следующий токен последовательности. Это является ключевой частью успеха языковых моделей. Качество решения задач на естественном языке зависит от размера модели (количества параметров) и от объема обучающей выборке. Используемых подход позволяет обучать модели на очень больших объемах текстовой информации без необходимости в ручной разметке данных.

Обученная на большом корпусе текстов языковая модель может выступать в качестве базовой модели для построения различных моделей для решения специфичных задач, таких как определение тональности текста, фильтрация текста, чат-боты и рекомендательные системы.

Следующим шагом развития моделей обработки естественного языка стало появление больших языковых моделей. Было обнаружено, что с ростом размера модели (количества параметров) и объема обучающей выборки, результаты моделей улучшаются. Более того, большие модели показали качественно отличное поведение от моделей меньшего размера. C определенного размера модели происходит значительный нелинейный рост производительности моделей в различных задачах. Данное явление было названо эмерджентным поведением \cite{llm_emergent}. Зависимость метрик в различных задачах обработки естественного языка от количества параметров модели представлена на рисунке \ref{img:llm_scaling}.

\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{../images/llm_scaling.png}
    \caption{Зависимость метрик в различных задачах обработки естественного языка от количества параметров модели \cite{llm_emergent}}
    \label{img:llm_scaling}
\end{figure}

\section{Использование больших языковых моделей в рекомендательных системах}

Выдающиеся способности больших языковых моделей в задачах обработки естественного языка привлекли внимание многих исследователей, и в настоящее время тема применения больших языковых моделей в задачах построения рекомендательных система активно исследуется \cite{do_llm_undertand_preferences, llm_rs_p5, llm_rs_survey}.

Большие языковые модели (LLM) обладают несколькими ключевыми преимуществами, которые делают их весьма эффективными в контексте рекомендательных систем.

Прежде всего, LLM проявляют высокий уровень понимания контекста, что делает их способными адаптироваться к сложным сценариям и улавливать тонкие нюансы в предоставленной информации. Это способствует повышению точности рекомендаций, учитывая текущий контекст и предпочтения пользователя.

Универсальность LLM проявляется в их способности решать различные рекомендательные задачи без необходимости создания отдельных алгоритмов для каждой из них. Это упрощает процесс интеграции модели в различные приложения и сценарии использования, снижая требования к инженерии.

LLM также эффективно справляются с проблемой холодного старта, обеспечивая качественные рекомендации, даже когда у пользователя ограниченный исторический след в системе. Это делает модели более устойчивыми и готовыми к предоставлению рекомендаций новым пользователям или тем, у кого ограниченный объем взаимодействий.

Преимущественное использование знаний, вложенных в модель, также выделяет LLM. Эти модели обладают обширными знаниями о мире, которые могут быть встроены в базовую модель, что снижает зависимость от конкретных обучающих датасетов. Это особенно полезно при обработке специфических сценариев, где требуются дополнительные знания.

Кроме того, LLM обеспечивают возможность объяснения принятых решений, что является важным аспектом для повышения доверия пользователей к рекомендациям. Модели могут предоставлять обоснование своих выводов, что помогает пользователям лучше понимать логику рекомендаций и повышает их удовлетворенность системой.

В сфере применения больших языковых моделей (LLM) в рекомендательных системах представлено множество подходов, нацеленных на повышение эффективности и точности рекомендаций. В разработке рекомендательных систем с применением LLM активно используются разнообразные стратегии.

Когда речь идет о учете предыдущих действий пользователей, существуют различные методы предоставления этой информации. Модель может быть дообучена или обучена с нуля на основе действий других пользователей, что дает ей способность предсказывать будущие действия, учитывая конкретные данные о рекомендациях. Альтернативно, подходы zero-shot и few-shot предусматривают использование модели без дополнительного обучения, позволяя ей анализировать предыдущие действия пользователя, переданные в промпт, и предоставлять рекомендации по команде.

В рамках общей архитектуры и использования LLM, эмбеддинги, созданные моделью, могут быть включены в классические алгоритмы рекомендательных систем или использоваться в алгоритмах top-K для поиска ближайших объектов. Также возможно использование текста, который подлежит классификации дополнительной моделью рекомендательной системы, а также непосредственный обмен текстовыми запросами и ответами, например, с использованием модели, аналогичной ChatGPT.

В разрезе методов обработки промптов выделяются conversational recommendations, основанные на запросе рекомендаций с описанием, sequential recommendations, использующие предыдущие действия пользователя для прогнозирования будущих рекомендаций, и rating predictions, где предыдущие оценки пользователя используются для прогнозирования оценок для следующих кандидатов. Подходы к оценке включают pointwise (присвоение рейтинга каждому элементу независимо), pairwise (выбор предпочтительного объекта из пары) и listwise (сортировка списка объектов).

Относительно представления входных данных, существует гибкость в выборе форматов, включая отсутствие входных данных, обработку обычного текста, а также использование токенов, представляющих действия пользователя. В этом случае вход модели формируется в виде последовательности этих действий, а не отдельных слов. Заявленные преимущества включают гибкость и динамичность, обеспечиваемые использованием промптов.

Одним из примеров использования большиъ языковых моделей для построения рекомнедательных систем является Bert4Rec. \cite{bert4rec}. Особенность Bert4Rec заключается в том, что модель обрабатывает не текстовую информацию, а последовательности действий пользователя с объектами. Входные данные для модели представляют собой именно эту последовательность, где каждое действие пользователя сопоставляется с соответствующим объектом. Процесс обучения Bert4Rec осуществляется с применением традиционной методологии обучения BERT с использованием Masked Language Modeling. Это позволяет модели эффективно изучать скрытые зависимости и закономерности в последовательности действий пользователя. В контексте предсказания, Bert4Rec использует обученную модель для прогнозирования следующего действия пользователя на основе предшествующей последовательности. Модель учитывает контекст и предпочтения пользователя, анализируя предыдущие шаги взаимодействия.

Другой вариант был представлен в статье \cite{transformers4rec}. В работе разработана библиотека, нацеленная на sequential session-based recommendation task. В работе был произведен анализ, какие архитектуры Трансформера и способы обучения лучше всего подходят. Лучшие модели обходят традиционные RS подходы в задачах рекомендаций товаров и новостей. Модель состоит из следующих частей: feature processing, sequence masking, sequence processing и prediction head. Шаг Feature Processing создает эмбеддинги на основе категориальных и числовых признаков. Шаг Sequence Masking осуществляет маскирование токенов для обучения с использованием Masked Language Modeling или Casual Language Modeling. Шаг Sequence Processing осущетсвляет основную обработку с использованием моделей Трансформера, реализованных с помощью библиотеки HaggingFace transformers. Затем осуществляется классификация полученного результата для принятия решения о рекомендации объекта.
